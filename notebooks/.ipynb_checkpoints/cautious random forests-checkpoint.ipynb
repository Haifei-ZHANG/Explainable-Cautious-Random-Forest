{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ec98ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "30d48f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CautiousRandomForest:\n",
    "    def __init__(self, n_trees=100, s=2, min_samples_leaf=1,combination='cdm-vote', discount_type='u65', random_state=42):\n",
    "        self.n_trees = n_trees\n",
    "        self.s = s\n",
    "        self.combination = combination\n",
    "        self.discount_type = discount_type\n",
    "        self.__discount_ratio = self.__define_discount_ratio(discount_type)\n",
    "        self.classes = None\n",
    "        self.n_class = None\n",
    "        self.__intervals_leaves = None\n",
    "        self.rf = RandomForestClassifier(n_estimators=n_trees, min_samples_leaf=min_samples_leaf, random_state=random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, train_X, train_y):\n",
    "        check_X_y(train_X, train_y)\n",
    "        \n",
    "        self.rf.fit(train_X, train_y)\n",
    "        \n",
    "        self.classes = self.rf.classes_\n",
    "        self.n_class = len(self.rf.classes_)\n",
    "\n",
    "        n_sample_leaves = {}\n",
    "        intervals_leaves = {}\n",
    "\n",
    "        for t in range(self.n_trees):\n",
    "            n_sample_leaves[t] = {}\n",
    "            intervals_leaves[t] = {}\n",
    "            tree = self.rf.estimators_[t]\n",
    "\n",
    "            n_nodes = tree.tree_.node_count\n",
    "            children_left = tree.tree_.children_left\n",
    "            children_right = tree.tree_.children_right\n",
    "            sample_count = tree.tree_.value.reshape((-1, self.n_class))\n",
    "\n",
    "            for i in range(n_nodes):\n",
    "                is_leaf_node = (children_left[i] == children_right[i])\n",
    "                if is_leaf_node:\n",
    "                    n_sample_leaves[t][i] = sample_count[i]\n",
    "                    n_total_sample = sum(sample_count[i])\n",
    "                    intervals = sample_count[i].repeat(2).reshape(self.n_class, 2)\n",
    "                    intervals[:,0] = intervals[:,0]/(n_total_sample + self.s)\n",
    "                    intervals[:,1] = (intervals[:,1] + self.s)/(n_total_sample + self.s)\n",
    "                    intervals_leaves[t][i] = intervals\n",
    "                    \n",
    "        self.__intervals_leaves = intervals_leaves\n",
    "        \n",
    "        \n",
    "    def __define_discount_ratio(self,i):\n",
    "        if self.discount_type == 'f1':\n",
    "            def discount_ratio(i):\n",
    "                return 2/(1+i)\n",
    "        elif self.discount_type == 'u80':\n",
    "            def discount_ratio(i):\n",
    "                return -1.2/(i**2) + 2.2/i\n",
    "        else:\n",
    "            def discount_ratio(i):\n",
    "                return -0.6/(i**2) + 1.6/i\n",
    "            self.discount_type = 'u65'\n",
    "        return discount_ratio\n",
    "        \n",
    "    \n",
    "    def __ndc(self, probabilities):\n",
    "        class_order = np.argsort(-probabilities)\n",
    "        max_eu = 0\n",
    "        top_k = 0\n",
    "        for k in range(1,self.n_class+1):\n",
    "            discount_ratio = self.__discount_ratio(k)\n",
    "            if discount_ratio < max_eu:\n",
    "                break\n",
    "            else:\n",
    "                probability_sum = np.sum(probabilities[class_order[0:k]])\n",
    "                eu = discount_ratio * probability_sum\n",
    "                if eu > max_eu:\n",
    "                    max_eu = eu\n",
    "                    top_k = k\n",
    "        \n",
    "        return list(self.classes[class_order[0:top_k]])\n",
    "    \n",
    "    \n",
    "    def __instance_interval_dominance(self, instance_intervals):\n",
    "        n_class = len(instance_intervals)\n",
    "        decision = []\n",
    "        for k in range(n_class):\n",
    "            other_classes = np.setdiff1d(np.arange(n_class), np.array([k]))\n",
    "            if np.any(instance_intervals[k, 1] < instance_intervals[other_classes, 0]):\n",
    "                continue\n",
    "            else:\n",
    "                decision.append(k)\n",
    "                \n",
    "        return decision\n",
    "    \n",
    "    \n",
    "    def __mva(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        vote_against = np.zeros(self.n_class)\n",
    "        for t in range(self.n_trees):\n",
    "            t_non_dominated_class = self.__instance_interval_dominance(intervals[t])\n",
    "            t_dominated_class = np.setdiff1d(np.arange(self.n_class), np.array(t_non_dominated_class))\n",
    "            for c in t_dominated_class:\n",
    "                vote_against[c] += 1\n",
    "        mva = vote_against.min()\n",
    "        predictions_index = np.where(vote_against==mva)[0]\n",
    "        \n",
    "        return list(self.classes[predictions_index])\n",
    "                \n",
    "    \n",
    "    def __ave(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        ave_intervals = intervals.mean(axis=0)\n",
    "        predictions_index = self.__instance_interval_dominance(ave_intervals)\n",
    "        \n",
    "        return list(self.classes[predictions_index])\n",
    "    \n",
    "    \n",
    "    def __cdm_ave(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        ave_intervals = intervals.mean(axis=0)\n",
    "        bels = ave_intervals[:,0]\n",
    "        class_order = np.argsort(-bels)\n",
    "        max_leu = 0\n",
    "        top_k = 0\n",
    "        for k in range(1,self.n_class+1):\n",
    "            discount_ratio = self.__discount_ratio(k)\n",
    "            if discount_ratio < max_leu:\n",
    "                break\n",
    "            else:\n",
    "                if k == self.n_class:\n",
    "                    bel = 1\n",
    "                else: \n",
    "                    bel = np.sum(bels[class_order[0:k]])\n",
    "                leu = discount_ratio * bel\n",
    "                if leu > max_leu:\n",
    "                    max_leu = leu\n",
    "                    top_k = k\n",
    "        return list(self.classes[class_order[0:top_k]])\n",
    "    \n",
    "    \n",
    "    def __cdm_slow_vote(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        mass_function = {}\n",
    "        for t in range(self.n_trees):\n",
    "            t_non_dominated_class = tuple(self.__instance_interval_dominance(intervals[t]))\n",
    "            if t_non_dominated_class not in list(mass_function.keys()):\n",
    "                mass_function[t_non_dominated_class] = 0\n",
    "            mass_function[t_non_dominated_class] += 1/self.n_trees\n",
    "\n",
    "        \n",
    "        max_leu = 0\n",
    "        prediction_index = None\n",
    "        focal_elements = list(mass_function.keys())\n",
    "        for k in range(1, self.n_class+1):\n",
    "            discount_ratio = self.__discount_ratio(k)\n",
    "            if discount_ratio < max_leu or k > 5:\n",
    "                break\n",
    "                \n",
    "            for subset_of_omega in itertools.combinations(np.arange(self.n_class), k):\n",
    "                if len(subset_of_omega) == 0:\n",
    "                    continue\n",
    "                \n",
    "                bel = 0\n",
    "                for focal_element in focal_elements:\n",
    "                    if set(focal_element).issubset(subset_of_omega):\n",
    "                        bel += mass_function[focal_element]\n",
    "                        \n",
    "                leu = discount_ratio * bel\n",
    "\n",
    "                if leu > max_leu:\n",
    "                    max_leu = leu\n",
    "                    prediction_index = subset_of_omega\n",
    "                    \n",
    "        return self.classes[list(prediction_index)]\n",
    "    \n",
    "    \n",
    "    def __cdm_vote(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        mass_function = {}\n",
    "        focal_elements = {}\n",
    "        considering_class_flag = np.zeros((self.n_class+1, self.n_class+1))\n",
    "        for t in range(self.n_trees):\n",
    "            t_non_dominated_class = tuple(self.__instance_interval_dominance(intervals[t]))\n",
    "            cardinality = len(t_non_dominated_class)\n",
    "            if cardinality not in list(mass_function.keys()):\n",
    "                mass_function[cardinality] = {}\n",
    "                focal_elements[cardinality] = []\n",
    "            if t_non_dominated_class not in list(mass_function[cardinality].keys()):\n",
    "                mass_function[cardinality][t_non_dominated_class] = 0\n",
    "                focal_elements[cardinality].append(t_non_dominated_class)\n",
    "                for c in t_non_dominated_class:\n",
    "                    considering_class_flag[cardinality, c] = 1\n",
    "            mass_function[cardinality][t_non_dominated_class] += 1/self.n_trees\n",
    "            \n",
    "        considering_class = {}\n",
    "        for k in range(1, self.n_class+1):\n",
    "            flag = considering_class_flag[:k+1].sum(axis=0)\n",
    "            considering_class[k] = np.where(flag>0)[0]\n",
    "            \n",
    "        max_leu = 0\n",
    "        prediction_index = None\n",
    "        for k in range(1, self.n_class+1):\n",
    "            discount_ratio = self.__discount_ratio(k)\n",
    "            if discount_ratio < max_leu or k > 5:\n",
    "                break\n",
    "            \n",
    "            possible_subsets = itertools.combinations(considering_class[k], k)\n",
    "            for subset in possible_subsets:\n",
    "                bel = 0\n",
    "                for i in range(1, k+1):\n",
    "                    if i not in list(focal_elements.keys()):\n",
    "                        continue\n",
    "                    else:\n",
    "                        for focal_element in focal_elements[i]:\n",
    "                            if set(focal_element).issubset(subset):\n",
    "                                bel += mass_function[i][focal_element]\n",
    "                        \n",
    "                leu = discount_ratio * bel\n",
    "\n",
    "                if leu > max_leu:\n",
    "                    max_leu = leu\n",
    "                    prediction_index = subset\n",
    "                    \n",
    "        return self.classes[list(prediction_index)]\n",
    "    \n",
    "        \n",
    "    def predict(self, X, dacc=None):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "            \n",
    "        predictions = []\n",
    "        n_instance = X.shape[0]\n",
    "        leaves_index = self.rf.apply(X)\n",
    "        \n",
    "        if self.combination == 'ndc':\n",
    "            all_proabilities = self.rf.predict_proba(X)\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.__ndc(all_proabilities[i]))\n",
    "            return predictions\n",
    "        \n",
    "        # get all [bel, pl] intervals for all instances, shape of (n_instance, T, n_class, 2)\n",
    "        all_intrvals = np.zeros((n_instance, self.n_trees, self.n_class, 2))\n",
    "        for i in range(n_instance):\n",
    "            for t in range(self.n_trees):\n",
    "                all_intrvals[i, t] = self.__intervals_leaves[t][leaves_index[i,t]]\n",
    "                \n",
    "        if self.combination == 'mva':\n",
    "            # MVA\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.__mva(all_intrvals[i]))\n",
    "            return predictions\n",
    "        \n",
    "        elif self.combination == 'ave':\n",
    "            # AVE\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.__ave(all_intrvals[i]))\n",
    "            return predictions\n",
    "        \n",
    "        elif self.combination == 'cdm-ave':\n",
    "            # generalized ave\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.__cdm_ave(all_intrvals[i]))\n",
    "            return predictions\n",
    "        \n",
    "        else:\n",
    "            # default cdm-vote\n",
    "            for i in tqdm(range(n_instance)):\n",
    "#                 predictions.append(self.__cdm_vote(all_intrvals[i]))\n",
    "                predictions.append(self.__cdm_slow_vote(all_intrvals[i]))\n",
    "            return predictions\n",
    "        \n",
    "        \n",
    "    def score(self, X_test, y_test):\n",
    "        # get both imprecise and precise predictions \n",
    "        predictions = self.predict(X_test)\n",
    "        determinacy = 0\n",
    "        single_accuracy = 0\n",
    "        set_accuracy = 0\n",
    "        set_size = 0\n",
    "        u65 = 0\n",
    "        f1 = 0\n",
    "        u80 = 0\n",
    "        for i in range(len(y_test)):\n",
    "            prediction = predictions[i]\n",
    "            if len(prediction) == 1:\n",
    "                determinacy += 1\n",
    "                \n",
    "                if prediction[0] == y_test[i]:\n",
    "                    single_accuracy += 1\n",
    "                    u65 += 1\n",
    "                    f1 += 1\n",
    "                    u80 += 1\n",
    "            else:\n",
    "                set_size += len(prediction)\n",
    "                if y_test[i] in prediction:\n",
    "                    set_accuracy += 1\n",
    "                    u65 += (-0.6/(len(prediction)**2) + 1.6/len(prediction))\n",
    "                    f1 += 2/(1+len(prediction))\n",
    "                    u80 += (-1.2/(len(prediction)**2) + 2.2/len(prediction))\n",
    "                    \n",
    "        n_determinate = determinacy\n",
    "        n_indeterminate = len(y_test) - determinacy\n",
    "        \n",
    "        determinacy /= len(y_test)\n",
    "        if n_determinate == 0:\n",
    "            single_accuracy = None\n",
    "        else:\n",
    "            single_accuracy /= n_determinate\n",
    "        if n_indeterminate == 0:\n",
    "            set_accuracy = None\n",
    "            set_size = None\n",
    "        else:\n",
    "            set_accuracy /= n_indeterminate\n",
    "            set_size /= n_indeterminate\n",
    "        u65 /= len(y_test)\n",
    "        f1 /= len(y_test)\n",
    "        u80 /= len(y_test)\n",
    "                \n",
    "        return {'determinacy': round(determinacy,4),\n",
    "                 'single accuracy': None if single_accuracy is None else round(single_accuracy,4),\n",
    "                 'set accuracy': None if set_accuracy is None else round(set_accuracy,4),\n",
    "                 'set size': None if set_size is None else round(set_size,4),\n",
    "                 'u65 score': round(u65,4),\n",
    "                 'f1 score': round(f1,4),\n",
    "                 'u80 score': round(u80,4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c0251f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/multi-class data/letter.csv\")\n",
    "X = np.array(data.iloc[:,:-1])\n",
    "y = np.array(data.iloc[:,-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "63a591af",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CautiousRandomForest(n_trees=100, s=2, min_samples_leaf=1,combination='cdm-vote', random_state=42)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8cba8426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 660/660 [03:43<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'determinacy': 0.8394, 'single accuracy': 0.8917, 'set accuracy': 0.6887, 'set size': 2.1226, 'u65 score': 0.8187, 'f1 score': 0.8207, 'u80 score': 0.8352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223.34713220596313"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "print(crf.score(X_test, y_test))\n",
    "et = time.time()\n",
    "\n",
    "et-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d141dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
