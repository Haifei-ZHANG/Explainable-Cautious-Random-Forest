{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import itertools\n",
    "import scipy.stats as stats\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import wilcoxon, ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble._forest import _generate_unsampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCCRF:\n",
    "    def __init__(self, n_trees=100, s=2, min_samples_leaf=1,combination=1, dacc='u65', data_name=None, random_state=42):\n",
    "        # build a random forest using sklearn RandomForestClassifier\n",
    "        self.n_trees = n_trees\n",
    "        self.s = s\n",
    "        self.combination = combination\n",
    "        self.dacc = dacc\n",
    "        self.data_name = data_name\n",
    "        self.w = np.ones(n_trees)/n_trees\n",
    "        self.classes = None\n",
    "        self.n_class = None\n",
    "        self.rf = RandomForestClassifier(n_estimators=n_trees, min_samples_leaf=min_samples_leaf, random_state=random_state, )\n",
    "        \n",
    "        \n",
    "    def fit(self, train_x, train_y):\n",
    "        self.rf.fit(train_x, train_y)\n",
    "        \n",
    "        self.classes = self.rf.classes_\n",
    "        self.n_class = len(self.rf.classes_)\n",
    "\n",
    "        n_sample_leaves = {}\n",
    "        intervals_leaves = {}\n",
    "\n",
    "        for t in range(self.n_trees):\n",
    "            n_sample_leaves[t] = {}\n",
    "            intervals_leaves[t] = {}\n",
    "            tree = self.rf.estimators_[t]\n",
    "\n",
    "            n_nodes = tree.tree_.node_count\n",
    "            children_left = tree.tree_.children_left\n",
    "            children_right = tree.tree_.children_right\n",
    "            sample_count = tree.tree_.value.reshape((-1, self.n_class))\n",
    "\n",
    "            for i in range(n_nodes):\n",
    "                is_leaf_node = (children_left[i] == children_right[i])\n",
    "                if is_leaf_node:\n",
    "                    n_sample_leaves[t][i] = sample_count[i]\n",
    "                    n_total_sample = sum(sample_count[i])\n",
    "                    intervals = sample_count[i].repeat(2).reshape(self.n_class, 2)\n",
    "                    intervals[:,0] = intervals[:,0]/(n_total_sample + self.s)\n",
    "                    intervals[:,1] = (intervals[:,1] + self.s)/(n_total_sample + self.s)\n",
    "                    intervals_leaves[t][i] = intervals\n",
    "                    \n",
    "        self.intervals_leaves = intervals_leaves\n",
    "\n",
    "    \n",
    "    def instance_interval_dominance(self, instance_intervals):\n",
    "        n_class = len(instance_intervals)\n",
    "        decision = []\n",
    "        for i in range(n_class):\n",
    "            other_classes = np.setdiff1d(np.arange(n_class), np.array([i]))\n",
    "            if np.any(instance_intervals[i, 1] < instance_intervals[other_classes, 0]):\n",
    "                continue\n",
    "            else:\n",
    "                decision.append(i)\n",
    "                \n",
    "        return decision\n",
    "    \n",
    "    \n",
    "    def mva(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        vote_against = np.zeros(self.n_class)\n",
    "        for t in range(self.n_trees):\n",
    "            t_non_dominated_class = self.instance_interval_dominance(intervals[t])\n",
    "            t_dominated_class = np.setdiff1d(np.arange(self.n_class), np.array(t_non_dominated_class))\n",
    "            for c in t_dominated_class:\n",
    "                vote_against[c] += 1\n",
    "        mva = vote_against.min()\n",
    "        predictions_index = np.where(vote_against==mva)[0]\n",
    "        \n",
    "        return self.classes[predictions_index]\n",
    "                \n",
    "    \n",
    "    def ave(self, intervals):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        ave_intervals = intervals.mean(axis=0)\n",
    "        predictions_index = self.instance_interval_dominance(ave_intervals)\n",
    "        \n",
    "        return self.classes[predictions_index]\n",
    "    \n",
    "    \n",
    "    def mldu_vote(self, intervals, dacc):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        mass_function = {}\n",
    "        for t in range(self.n_trees):\n",
    "            t_non_dominated_class = tuple(self.instance_interval_dominance(intervals[t]))\n",
    "            if t_non_dominated_class not in list(mass_function.keys()):\n",
    "                mass_function[t_non_dominated_class] = 0\n",
    "            mass_function[t_non_dominated_class] += 1/self.n_trees\n",
    "\n",
    "        \n",
    "        max_ledu = 0\n",
    "        prediction_index = None\n",
    "        focal_elements = list(mass_function.keys())\n",
    "#         print(mass_function)\n",
    "        for l in range(1, self.n_class+1):\n",
    "            if len(subset_of_omega)> 5:\n",
    "                return self.classes[list(prediction_index)]\n",
    "            for subset_of_omega in itertools.combinations(np.arange(self.n_class), l):\n",
    "                if len(subset_of_omega) == 0:\n",
    "                    continue\n",
    "                \n",
    "                bel = 0\n",
    "                for focal_element in focal_elements:\n",
    "                    if set(focal_element).issubset(subset_of_omega):\n",
    "                        bel += mass_function[focal_element]\n",
    "                        \n",
    "                if dacc == 'u80':\n",
    "                    ledu = bel * (-1.2/(l**2) + 2.2/l)\n",
    "                else:\n",
    "                    # defautl u65\n",
    "                    ledu = bel * (-0.6/(l**2) + 1.6/l)\n",
    "\n",
    "#                     print(subset_of_omage, bel, ledu)\n",
    "\n",
    "                if ledu > max_ledu:\n",
    "                    max_ledu = ledu\n",
    "                    prediction_index = subset_of_omega\n",
    "\n",
    "            if max_ledu > -0.6/((l+1)**2) + 1.6/(l+1) or max_ledu < 0.1:\n",
    "                break\n",
    "        return self.classes[list(prediction_index)]\n",
    "    \n",
    "    \n",
    "    def mldu_ave(self, intervals, dacc):\n",
    "        # intervals here is numpy array of shape (T, n_class, 2)\n",
    "        ave_intervals = intervals.mean(axis=0)\n",
    "        bels = ave_intervals[:,0]\n",
    "        class_order = np.argsort(-bels)\n",
    "        max_ldu = 0\n",
    "        for l in range(1, self.n_class+1):\n",
    "            if l == self.n_class:\n",
    "                bel = 1\n",
    "            else:\n",
    "                bel = bels[class_order[:l]].sum()\n",
    "            if dacc == 'u80':\n",
    "                ldu = bel * (-1.2/(l**2) + 2.2/l)\n",
    "            else:\n",
    "                # defautl u65\n",
    "                ldu = bel * (-0.6/(l**2) + 1.6/l)\n",
    "            if ldu > max_ldu:\n",
    "                max_ldu = ldu\n",
    "                predictions_index = class_order[:l]\n",
    "        return self.classes[predictions_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X, dacc=None):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        if dacc is None:\n",
    "            dacc = self.dacc\n",
    "        predictions = []\n",
    "        n_instance = X.shape[0]\n",
    "        leaves_index = self.rf.apply(X)\n",
    "        \n",
    "        # get all [bel, pl] intervals for all instances, shape of (n_instance, T, c_class, 2)\n",
    "        all_intrvals = np.zeros((n_instance, self.n_trees, self.n_class, 2))\n",
    "        for i in range(n_instance):\n",
    "            for t in range(self.n_trees):\n",
    "                all_intrvals[i, t] = self.intervals_leaves[t][leaves_index[i,t]]\n",
    "                \n",
    "        if self.combination == 1:\n",
    "            # MVA\n",
    "            predictions = []\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.mva(all_intrvals[i]))\n",
    "            return predictions\n",
    "        \n",
    "        if self.combination == 2:\n",
    "            # AVE\n",
    "            predictions = []\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.ave(all_intrvals[i]))\n",
    "            return predictions\n",
    "            \n",
    "        if self.combination == 3:\n",
    "            # generalized vote\n",
    "            predictions = []\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.mldu_vote(all_intrvals[i], dacc))\n",
    "            return predictions\n",
    "        \n",
    "        if self.combination == 4:\n",
    "            # generalized ave\n",
    "            predictions = []\n",
    "            for i in range(n_instance):\n",
    "                predictions.append(self.mldu_ave(all_intrvals[i], dacc))\n",
    "            return predictions\n",
    "    \n",
    "        \n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        # get both imprecise and precise predictions \n",
    "        predictions = self.predict(X_test)\n",
    "        determinacy = 0\n",
    "        single_set_accuracy = 0\n",
    "        set_accuracy = 0\n",
    "        set_size = 0\n",
    "        u65 = 0\n",
    "        u80 = 0\n",
    "        for i in range(len(y_test)):\n",
    "            prediction = predictions[i]\n",
    "            if len(prediction) == 1:\n",
    "                determinacy += 1\n",
    "                if prediction[0] == y_test[i]:\n",
    "                    single_set_accuracy += 1\n",
    "                    u65 += 1\n",
    "                    u80 += 1\n",
    "            else:\n",
    "                set_size += len(prediction)\n",
    "                if y_test[i] in prediction:\n",
    "                    set_accuracy += 1\n",
    "                    u65 += (-0.6/(len(prediction)**2) + 1.6/len(prediction))\n",
    "                    u80 += (-1.2/(len(prediction)**2) + 2.2/len(prediction))\n",
    "                    \n",
    "        n_determinate = determinacy\n",
    "        n_indeterminate = len(y_test) - determinacy\n",
    "        \n",
    "        determinacy /= len(y_test)\n",
    "        single_set_accuracy /= n_determinate\n",
    "        if n_indeterminate == 0:\n",
    "            set_accuracy = -1\n",
    "            set_size = -1\n",
    "        else:\n",
    "            set_accuracy /= n_indeterminate\n",
    "            set_size /= n_indeterminate\n",
    "        u65 /= len(y_test)\n",
    "        u80 /= len(y_test)\n",
    "                \n",
    "        return {'determinacy': determinacy,\n",
    "                 'single set accuracy': single_set_accuracy,\n",
    "                 'set accuracy': set_accuracy,\n",
    "                 'set size': set_size,\n",
    "                 'u65 score': u65, \n",
    "                 'u80 score': u80}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/vehicle.csv\")\n",
    "X = np.array(data.iloc[:,:-1])\n",
    "y = np.array(data.iloc[:,-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = MCCRF(n_trees=100, s=1, min_samples_leaf=1,combination=1, data_name=None, random_state=42)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'determinacy': 0.9928571428571429,\n",
       " 'single set accuracy': 0.7733812949640287,\n",
       " 'set accuracy': 1.0,\n",
       " 'set size': 2.0,\n",
       " 'u65 score': 0.7725000000000001,\n",
       " 'u80 score': 0.7735714285714287}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.combination = 1\n",
    "eva = crf.evaluate(X_test, y_test)\n",
    "eva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_names = ['balance_scale', 'ecoli', 'optdigits', 'page_blocks',\n",
    "             'pendigits', 'segment', 'vehicle', 'vowel', 'waveform', 'wine']\n",
    "data_names = ['letter']\n",
    "combinations = [1, 2, 3, 4]\n",
    "it = 10\n",
    "k = 10\n",
    "\n",
    "for d in range(len(data_names)):\n",
    "    data_name = data_names[d]\n",
    "    data = pd.read_csv('data/{}.csv'.format(data_name))\n",
    "    X = np.array(data.iloc[:,:-1])\n",
    "    y = np.array(data.iloc[:,-1])\n",
    "    evaluation_for_data = np.zeros((6, it*k, 4))\n",
    "    for i in tqdm(range(it)):\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        j = 0\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            crf = MCCRF(n_trees=100, s=2, min_samples_leaf=1,combination=1, data_name=None, random_state=None)\n",
    "            crf.fit(X_train, y_train)\n",
    "            \n",
    "            for c in combinations:\n",
    "                crf.combination = c\n",
    "                eva = crf.evaluate(X_test, y_test)\n",
    "                eva = np.array(list(eva.values())).round(4)\n",
    "                evaluation_for_data[:,i*k+j ,c-1] = eva\n",
    "            \n",
    "            j += 1\n",
    "    \n",
    "#     np.save('results/{}_evaluation.npy'.format(data_name), evaluation_for_data)\n",
    "print(evaluation_for_data.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Level: 5\n",
      "0 balance_scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:56<00:00, 17.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ecoli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:37<00:00, 21.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 optdigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [25:39<00:00, 153.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 page_blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [13:58<00:00, 83.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 pendigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [25:12<00:00, 151.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 segment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [18:28<00:00, 110.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 vehicle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:55<00:00, 29.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 vowel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:03<00:00, 84.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 waveform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [09:36<00:00, 57.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Level: 10\n",
      "0 balance_scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:05<00:00, 18.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ecoli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:37<00:00, 21.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 optdigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [26:03<00:00, 156.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 page_blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [15:40<00:00, 94.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 pendigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [25:11<00:00, 151.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 segment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [18:23<00:00, 110.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 vehicle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:58<00:00, 29.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 vowel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:06<00:00, 84.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 waveform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [09:25<00:00, 56.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:56<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Level: 15\n",
      "0 balance_scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:01<00:00, 18.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ecoli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:37<00:00, 21.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 optdigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [25:32<00:00, 153.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 page_blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:06<00:00, 84.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 pendigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [26:26<00:00, 158.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 segment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [19:02<00:00, 114.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 vehicle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:58<00:00, 29.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 vowel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:26<00:00, 86.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 waveform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [09:30<00:00, 57.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Level: 20\n",
      "0 balance_scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:09<00:00, 18.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ecoli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:40<00:00, 22.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 optdigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [26:16<00:00, 157.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 page_blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [14:15<00:00, 85.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 pendigits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [26:48<00:00, 160.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 segment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [19:48<00:00, 118.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 vehicle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [05:23<00:00, 32.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 vowel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [15:32<00:00, 93.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 waveform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [09:45<00:00, 58.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.76s/it]\n"
     ]
    }
   ],
   "source": [
    "data_names = ['balance_scale', 'ecoli', 'optdigits', 'page_blocks',\n",
    "             'pendigits', 'segment', 'vehicle', 'vowel', 'waveform', 'wine']\n",
    "noise_levels = [5, 10, 15, 20]\n",
    "combinations = [1,2,3,4]\n",
    "it = 10\n",
    "k = 10\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    print('Noise Level:', noise_level)\n",
    "    for d in range(len(data_names)):\n",
    "        data_name = data_names[d]\n",
    "        print(d, data_name)\n",
    "        data = pd.read_csv('data/{}.csv'.format(data_name))\n",
    "        X = np.array(data.iloc[:,:-1])\n",
    "        y = np.array(data.iloc[:,-1])\n",
    "        classes = np.unique(y)\n",
    "        evaluation_for_data = np.zeros((6, it*k, 4))\n",
    "        for i in tqdm(range(it)):\n",
    "            kf = KFold(n_splits=k, shuffle=True)\n",
    "            j = 0\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                \n",
    "                # in X_train, choose certain proportion of instance to change its label\n",
    "                instance_select = np.random.choice(len(y_train),int(noise_level*len(y_train)/100),replace=False)\n",
    "                for instance_index in instance_select:\n",
    "                    candidate_y = np.setdiff1d(classes, y_train[instance_index])\n",
    "                    y_train[instance_index] = candidate_y[np.random.choice(len(candidate_y), 1)[0]]\n",
    "                    \n",
    "                crf = MCCRF(n_trees=100, s=2, min_samples_leaf=1,combination=1, data_name=None, random_state=None) #dacc='u65'\n",
    "                crf.fit(X_train, y_train)\n",
    "\n",
    "                for c in combinations:\n",
    "                    crf.combination = c\n",
    "                    eva = crf.evaluate(X_test, y_test)\n",
    "                    eva = np.array(list(eva.values())).round(4)\n",
    "                    evaluation_for_data[:,i*k+j ,c-1] = eva\n",
    "\n",
    "                j += 1\n",
    "\n",
    "        np.save('results/{}_noise/{}_evaluation.npy'.format(noise_level,data_name), evaluation_for_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
